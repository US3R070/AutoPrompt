annotator:
    method: ''

dataset:
    records_path: 'dataset/generation_dataset.csv'
    initial_dataset: 'dataset/generation_dataset.csv'
    # label_schema: ["1","2","3","4","5"]
    max_samples: 20
    semantic_sampling: False

predictor:
    method : 'llm'
    config:
        prompt: 'prompts/predictor_completion/prediction_generation.prompt'
        mini_batch_size: 1
        llm:
            type: 'OpenAI'
            name: 'gpt-4o-mini' #'gpt-3.5-turbo-1106'
            temperature: 1.0
        num_workers: 7

llm:
    name: 'gpt-4o-mini' # This is the meta-prompt LLM, it should be a strong model. For example, using GPT-3.5 will cause an error in many cases.
    type: 'OpenAI' # Can be OpenAI, Anthropic, Google, Azure
    temperature: 0.8

meta_prompts:
    folder: 'prompts/meta_prompts_generation'
    warmup: 1

eval:
    function_name: 'ranking'
    error_threshold: 3
    num_large_errors: 3

few_shot_examples: 5