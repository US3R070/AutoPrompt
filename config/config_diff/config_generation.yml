annotator:
    method: ''

dataset:
    records_path: 'dataset/decider.csv'
    initial_dataset: 'dataset/decider.csv'
    label_schema: ["1","2","3","4","5"]
    max_samples: 20
    semantic_sampling: False

# predictor:
#     method : 'llm'
#     config:
#         prompt: 'prompts/predictor_completion/prediction_generation.prompt'
#         mini_batch_size: 1
#         llm:
#             type: 'OpenAI'
#             name: 'gpt-4o-mini' #'gpt-3.5-turbo-1106'
#             temperature: 1.0
#         num_workers: 7
predictor:
    method: 'llm'
    config:
        llm:
            type: 'Ollama'
            name: 'gemma3:4b-it-qat'
            base_url: 'https://is-alvin-ollama.intersense.work/'
            temperature: 0.0
        num_workers: 2
        prompt: 'prompts/predictor_completion/prediction.prompt'
        mini_batch_size: 1
        mode: 'prediction'

# llm:
#     name: 'gpt-4o-mini' # This is the meta-prompt LLM, it should be a strong model. For example, using GPT-3.5 will cause an error in many cases.
#     type: 'OpenAI' # Can be OpenAI, Anthropic, Google, Azure
#     temperature: 0.8

llm:
    type: 'Ollama'
    name: 'gemma3:4b-it-qat'
    base_url: 'https://is-alvin-ollama.intersense.work/'
    temperature: 0.0

meta_prompts:
    folder: 'prompts/meta_prompts_generation'
    warmup: 1

eval:
    function_name: 'ranking'
    error_threshold: 3
    num_large_errors: 3

few_shot_examples: 1