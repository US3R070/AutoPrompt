use_wandb: False

dataset:
    name: 'classification_dataset'
    records_path: 'dataset/classification_dataset.csv'
    initial_dataset: 'dataset/classification_dataset.csv'
    label_schema: ['True', 'False']
    max_samples: 30
    semantic_sampling: False

annotator:
    method: 'llm'
    config:
        llm:
            type: 'OpenAI'
            name: 'o4-mini'
            # model_kwargs: {"seed": 220}
            temperature: 1
        num_workers: 3
        prompt: 'prompts/predictor_completion/annotation.prompt'
        mini_batch_size: 1
        mode: 'annotation'

reasoner:
    method: 'llm'
    config:
        llm:
            type: 'OpenAI'
            name: 'gpt-4o'
            # model_kwargs: {"seed": 220}
            temperature: 1
        num_workers: 3


# reasoner:
#     method: 'llm'
#     config:
#         llm:
#             type: 'Ollama'
#             name: 'qwen3:8b'
#             base_url: 'https://ollama.havenook.com'
#             # model_kwargs: {"seed": 220}
#             temperature: 1
#         num_workers: 3

# predictor:
#     method: 'llm'
#     config:
#         llm:
#             type: 'OpenAI'
#             name: 'gpt-4o'
#             # model_kwargs: {"seed": 220}
#         num_workers: 3
#         prompt: 'prompts/predictor_completion/prediction.prompt'
#         mini_batch_size: 1
#         mode: 'prediction'

predictor:
    method: 'llm'
    config:
        llm:
            type: 'Ollama'
            name: 'qwen3:8b'
            base_url: 'https://ollama.havenook.com'
            # model_kwargs: {"temperature": 0}
            temperature: 0
        num_workers: 2
        prompt: 'prompts/predictor_completion/prediction.prompt'
        mini_batch_size: 1
        mode: 'prediction'

meta_prompts:
    folder: 'prompts/meta_prompts_classification'
    num_err_prompt: 2
    num_err_samples: 3
    history_length: 3
    num_generated_samples: 8
    num_initialize_samples: 8
    samples_generation_batch: 4
    num_workers: 3
    warmup: 3

eval:
    function_name: 'accuracy'
    num_large_errors: 3
    num_boundary_predictions: 0
    error_threshold: 0.5

llm:
    name: 'gpt-4.1'
    type: 'OpenAI'
    temperature: 1

stop_criteria:
    max_usage: 5
    patience: 8
    min_delta: 0.02 